#summary Instructions for running the scripts and producing Trigger Validation Shift reports.

<wiki:toc max_depth="1" />

= Introduction =

This package includes two scripts: 
  * *./run.py* - generates an HTML page that will form the basis of your shift report. This includes some introductory sentences, as well as a detailed report of all failed tests and corresponding bugs, as well as tests (and bugs) that were fixed between yesterday's and today's releases.
  * *./rtt.py* - parses the RTT summary page and reports all tests that showed a memory usage regression.

= Prerequisites =
  * A unix machine (either Linux or Mac)
  * A recent Python installation (2.6 or above)
  * [http://www.crummy.com/software/BeautifulSoup/ BeautifulSoup]
    * Note that you must install Beautiful Soup 3, and not the newer Beautiful Soup 4 version!
    * Make sure you can _import !BeautifulSoup_ inside the interpreter
    * *Update* April 24, 2012: Beautiful Soup is now included in svn, so you don't need to manually download and install it!

= Suggested procedure =
  # Make sure _configure_nightlies.py_ contains all nightlies that you are expected to check, per instructions posted on the trigger [https://twiki.cern.ch/twiki/bin/viewauth/Atlas/TriggerValidation twiki]
  # Change release number in *run.py* and *rtt.py* (the variable name is _rel_). This step is optional because you can also specify the release number on the command line.
  # Make sure there are no "unswept" bugs added in *run.py* via add_new method (search _NEW BUGS_ to find the relevant piece of code). If you do find some unswept bugs, please put them inside *Bug.py* in the _!BugTracker.prefill_ function. Remember to change add_new() to simple add().
  # Run _./run.py REL (PART) (DBY)_. REL is release number (from 0 = Sunday, until 6=Saturday). PART is an optional integer argument that selects only a subset of nightlies. Selecting PART=1 runs over the two nightlies that usually finish by midnight Chicago time. Selecting PART=2 runs over several nightlies that finish by 8 AM Chicago time. Selecting PART=3 runs over the last two nightlies that finish around 1 PM Chicago time. Selecting PART=0 runs over all nightlies, and is actually equivalent to running without the optional PART argument. Lastly, DBY is an optional argument that, when set to 1, instructs the script to compare today's ATN test results with the Day-Before-Yesterday's (DBY) cache results. If DBY is not specified (i.e. the default case), today's results are compared with Yesterday's cache. DBY option is useful in cases when yesterday's caches were not built, thus preventing generation of today's report because it cannot access yesterday's results to find fixed bugs.
  # Note that if some nightlies haven't actually finished, the _./run.py_ script will simply skip them and produce a report only for those nightlies that have finished. The output is saved directly to an html file, which can be copied to a local machined and viewed through a web browser (e.g., Google Chrome).
  # Check the generated shift report inside _index.html_. Pay particular attention to sections labeled <font color="yellow">*FIXME*</font> - these are the test failures that could not be matched against known bugs. For each of those cases, you need to either manually find a similar bug in the Savannah, or create a new bug. In either case, you need to let the script know about these previously unknown bugs. The preferred way is to add them in _run.py_ via the _add_new_ mechanism described above, but sweep them into the general bug repository (in _Bug.py_) in the end of the shift.
   # It is good practice check that any test that is matched as "new", even if it is matched to an old bug, to make sure that it is a correct match.  The strings used for the bug matching could be loose enough to catch unrelated bugs.
  # If you have a bug that can only be matched with a string in the full log file, that's OK as long as there aren't too many bugs that require full log. Because full logs are very large and take forever to download, run.py limits your to 10 full-log matches per invocation. If you really need to increases this limit (at the expense of run time), you can find the corresponding setting in Project.py.
  # Once you've identified and added the new bugs, rerun _./run.py_ to generate the final report. All bugs added via the _add_new_ mechanism will be automatically listed near the top of the generated report.
  # Run _./rtt.py 0_, and then repeat with an argument _1_ and _2_ to parse the other two RTT reports. Each time, it will print a report containing all memory usage regressions. Note that the output is dumped to screen - you will need to manually copy it into your shift report. By default, this script will identify the tests with a memory usage that's at least 10% higher than the _maximum_ usage in the past 6 days.

= Code organization =

*Nightly --> Project --> Test <-- Bug*

  * *Nightly (Nightly.py) * - refers to one ATLAS nightly (17.1.X.Y-VAL-P1HLT, 17.X.0 etc). You can find a complete list of all available nightlies on the [http://atlas-computing.web.cern.ch/atlas-computing/links/distDirectory/nightlies/global/nightly.html NICOS global page] ("Nightly Title" column). The nightlies that are the subject of your validation shift should be listed in _configure_nightlies.py_.
  * *Project (Project.py) * - refers to a test suit project associated with a given nightly (!TrigP1Test, !TriggerTest, or !TrigAnalysisTest). For each project in a given nightly, you must provide a link to its ATN test summary page in _configure_nightlies.py_.
  * *Test (Test.py)* - refers to one unit test within a Project. For example, this [http://atlas-computing.web.cern.ch/atlas-computing/links/buildDirectory/nightlies/17.1.X.Y.Z-VAL/AtlasCAFHLT/rel_4/NICOS_area/NICOS_atntest171XYZVALAtlasCAFHLT32BS5G4AtlasCAFHLTOpt/triggertest_testconfiguration_work/ ATN page] for !TriggerTest project shows several unit tests that should be checked by the shifter.
  * *Bug (Bug.py)* - refers to a specific bug on the [https://savannah.cern.ch/bugs/?group=atlas-trig Savannah] bug tracker.
  * *!BugTracker (Bug.py)* - refers to a local repository of bugs hardcoded in Bug.py. Basically, all common bugs that appeared in the last few days are entered into this local bug database along with unique "greppable" strings that can be used to identify each bug from the log files.

= Adding new bugs =
If you detect a test failure that could not be matched against the existing bug database in _Bug.py_, please add a corresponding entry for future users. It is also likely that this would save you time tomorrow, because bugs are rarely fixed within one day of appearance.

Basically, once you identify a unique pattern in the log extract (either tail or error extracts are fine), add them inside *run.py* via _bugs.add_new()_. This way, these new bugs will be automatically included at the top of your shift report, as requested by the shift leader.

In the end of the shift, please sweep all new bugs inside the !BugTracker database inside *Bug.py*. The relevant function is _!BugTracker.prefill()_.

A useful note: once you add a bug to the _!BugTracker.prefill()_ function, you can quickly test if it matches a given log file (in other words, that the pattern you chose for this bug is not too restrictive) by running:
{{{
./Bug.py http://www.link.to/bug/log/fragment
}}}
If the pattern was entered correctly, you should see a match.

Be very careful not to add too-general patterns that might match the wrong bug. If unsure, you can always include multiple pattern fragments - the pattern matching machinery will require that *all* fragments must match in a given log file. Also, make sure to escape "[","]","(",")" and other special regex characters.

You usually don't need to give a human-readable description of the bug; that information (i.e., the bug title) is automatically fetched from the Savannah tracker. However, sometimes it's useful to provide an explicit note. In that case, just set the "comment=" variable when you add an entry for a new bug.
{{{
bugs.add(88554,['Moving to AthenaTrigRDO_chainOrder_compare','differences in tests with ordered HLT chain execution','TrigSteer_EF.TrigChainMoniValidation'],comment='Bugtracker says this bug reports small changes in HLT chain execution, which are expected.')
}}}

= In case of problems =
By default, the code is configured to gracefully skip all nightlies that cause a fatal error. In this case, a message similar to the following one is printed to screen:
{{{
WARNING: skipping release 17.1.X.Y.Z-VAL2-AtlasCAFHLT (32-bit)
}}}
Most often, this happens when one of the test suites hasn't finished running yet. In particular, the VAL2-AtlasCAFHLT sometimes only finishes around noon (Chicago time).

If you waited long enough and still cannot process a particular release, you can enable a detailed traceback by re-raising the exception, which can be accomplished by setting SKIP_ERRORS=False at the top of run.py. It will print a line number that caused the crash, and you'll be able to add additional debug printouts just before it to further understand the cause of the problem.