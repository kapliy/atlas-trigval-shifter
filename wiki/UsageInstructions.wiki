#summary Instructions for running the scripts and producing Trigger Validation Shift reports.

<wiki:toc max_depth="1" />

= Introduction =

This package includes two scripts: 
  * *./run.py* - generates an HTML page that will form the basis of your shift report. This includes some introductory sentences, as well as a detailed report of all failed tests and corresponding bugs, as well as tests (and bugs) that were fixed between yesterday's and today's releases.
  * *./rtt.py* - parses the RTT summary page and reports all tests that showed a memory usage regression.

= Prerequisites =
  * A unix machine (either Linux or Mac)
  * A recent Python installation (2.6 or above)
  * [http://www.crummy.com/software/BeautifulSoup/ BeautifulSoup]
    * Make sure you can _import !BeautifulSoup_ inside the interpreter

= Suggested procedure =
  # Make sure _configure_nightlies.py_ contains all nightlies that you are expected to check, per instructions posted on the trigger [https://twiki.cern.ch/twiki/bin/viewauth/Atlas/TriggerValidation twiki]
  # Change release number in *run.py* and *rtt.py* (the variable name is _rel_)
  # Make sure there are no "unswept" bugs added in *run.py* via add_new method (search _NEW BUGS_ to find the relevant piece of code). If you do find some unswept bugs, please put them inside *Bug.py* in the _!BugTracker.prefill_ function. Remember to change add_new() to simple add().
  # Run _./run.py_. Note that if some nightlies haven't finished, the script will simply skip them and produce a report only for those nightlies that have finished. The output is saved directly to an html file, which should be put into your public_html/ and viewed through a web browser.
  # Check the generated shift report inside _index.html_. Pay particular attention to sections labeled <font color="yellow">*FIXME*</font> - these are the test failures that could not be matched against known bugs. For each of those cases, you need to either manually find a similar bug in the Savannah, or create a new bug. In either case, update the *Bug.py* !BugTracker class with the new bug records and matching patterns. Make sure to record somewhere the newly created Savannah bugs so you can report them in the beginning of the shift summary report.
  # Run _./rtt.py 0_, and then repeat with an argument _1_ and _2_ to parse the other two RTT reports. Each time, it will print a report containing all memory usage regressions. Note that the output is dumped to screen - you will need to manually copy it into your shift report. By default, this script will identify the tests with a memory usage at least 10% higher than the maximum usage in the past 6 days.


= Code organization =

*Nightly --> Project --> Test <-- Bug*

  * *Nightly (Nightly.py) * - refers to one ATLAS nightly (17.1.X.Y-VAL-P1HLT, 17.X.0 etc). You can find a complete list of all available nightlies on the [http://atlas-computing.web.cern.ch/atlas-computing/links/distDirectory/nightlies/global/nightly.html NICOS global page] ("Nightly Title" column). The nightlies that are the subject of your validation shift should be listed in _configure_nightlies.py_.
  * *Project (Project.py) * - refers to a test suit project associated with a given nightly (!TrigP1Test, !TriggerTest, or !TrigAnalysisTest). For each project in a given nightly, you must provide a link to its ATN test summary page in _configure_nightlies.py_.
  * *Test (Test.py)* - refers to one unit test within a Project. For example, this [http://atlas-computing.web.cern.ch/atlas-computing/links/buildDirectory/nightlies/17.1.X.Y.Z-VAL/AtlasCAFHLT/rel_4/NICOS_area/NICOS_atntest171XYZVALAtlasCAFHLT32BS5G4AtlasCAFHLTOpt/triggertest_testconfiguration_work/ ATN page] for !TriggerTest project shows several unit tests that should be checked by the shifter.
  * *Bug (Bug.py)* - refers to a specific bug on the [https://savannah.cern.ch/bugs/?group=atlas-trig Savannah] bug tracker.
  * *!BugTracker (Bug.py)* - refers to a local repository of bugs hardcoded in Bug.py. Basically, all common bugs that appeared in the last few days are entered into this local bug database along with unique "greppable" strings that can be used to identify each bug from the log files.

= Adding new bugs =
If you detect a test failure that could not be matched against the existing bug database in _Bug.py_, please add a corresponding entry for future users. It is also likely that this would save you time tomorrow, because bugs are rarely fixed within one day of appearance.

Basically, once you identify a unique pattern in the log extract (either tail or error extracts are fine), add them inside *run.py* via _bugs.add_new()_. This way, these new bugs will be automatically included at the top of your shift report, as requested by the shift leader.

In the end of the shift, please sweep all new bugs inside the !BugTracker database inside *Bug.py*. The relevant function is _!BugTracker.prefill()_.

A useful note: once you add a bug to the _!BugTracker.prefill()_ function, you can quickly test if it matches a given log file (in other words, that the pattern you chose for this bug is not too restrictive) by running:
{{{
./Bug.py http://www.link.to/bug/log/fragment
}}}
If the pattern was entered correctly, you should see a match.

Be very careful not to add too-general patterns that might match the wrong bug. If unsure, you can always include multiple pattern fragments - the pattern matching machinery will require that *all* fragments must match in a given log file. Also, make sure to escape "[","]","(",")" and other special regex characters.

You usually don't need to give a human-readable description of the bug; that information (i.e., the bug title) is automatically fetched from the Savannah tracker. However, sometimes it's useful to provide an explicit note. In that case, just set the "comment=" variable when you add an entry for a new bug.
{{{
bugs.add(88554,['Moving to AthenaTrigRDO_chainOrder_compare','differences in tests with ordered HLT chain execution','TrigSteer_EF.TrigChainMoniValidation'],comment='Bugtracker says this bug reports small changes in HLT chain execution, which are expected.')
}}}

= In case of problems =
By default, the code is configured to gracefully skip all nightlies that cause a fatal error. In this case, a message similar to the following one is printed to screen:
{{{
WARNING: skipping release 17.1.X.Y.Z-VAL2-AtlasCAFHLT (32-bit)
}}}
Most often, this happens when one of the test suites hasn't finished running yet. In particular, the VAL2-AtlasCAFHLT sometimes only finishes around noon (Chicago time).

If you waited long enough and still cannot process a particular release, you can enable a detailed traceback by re-raising the exception near the bottom of run.py (search for _enable for debugging_).