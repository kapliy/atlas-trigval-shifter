#summary Instructions for running the scripts and producing Trigger Validation Shift reports.

= Introduction =

This package includes two scripts: 
  * *./run.py* - generates an HTML page that will form the basis of your shift report. This includes some introductory sentences, as well as a detailed report of all failed tests and corresponding bugs.
  * *./rtt.py* - parses the RTT summary page and reports all tests that used a lot of memory with respect to previous few days.

= Suggested procedure =
  # Make sure _configure_nightlies.py_ contains all nightlies that you are expected to check, per instructions posted on the trigger [https://twiki.cern.ch/twiki/bin/viewauth/Atlas/TriggerValidation twiki]
  # Change release number in *run.py* and *rtt.py* (the variable name is _rel_)
  # Run _./run.py_. Note that if some nightlies haven't finished running the unit tests, the script will still produce a shift report for those nightlies that have finished. Note that the output is saved directly to an html file.
  # Check the generated shift report inside _index.html_. Pay particular attention to sections labeled "FIXME" - these are the test failures that could not be matched against known bugs. For each of those cases, you need to either manually find a similar bug in the Savannah, or create a new bug. In either case, update the *Bug.py* !BugTracker class with the new bug records and matching patterns. Make sure to record somewhere the newly created Savannah bugs so you can report them in the beginning of the shift summary report.
  # Run _./rtt.py 0_, and then the same with an argument "1" and "2". Each time, it will print a report containing all memory usage regressions. Note that the output is dumped to screen - you will need to manually copy it into your shift report.


= Code organization =

*Nightly --> Project --> Test <-- Bug*

  * *Nightly (Nightly.py) * - refers to one ATLAS nightly (17.1.X.Y-VAL-P1HLT, 17.X.0 etc). You can find a complete list of all available nightlies on the [http://atlas-computing.web.cern.ch/atlas-computing/links/distDirectory/nightlies/global/nightly.html NICOS global page] ("Nightly Title" column). The nightlies that are the subject of your validation shift should be listed in _configure_nightlies.py_.
  * *Project (Project.py) * - refers to a test suit project associated with a given nightly (!TrigP1Test, !TriggerTest, or !TrigAnalysisTest). For each project in a given nightly, you must provide a link to its ATN test summary page in _configure_nightlies.py_.
  * *Test (Test.py)* - refers to one unit test within a Project. For example, this [http://atlas-computing.web.cern.ch/atlas-computing/links/buildDirectory/nightlies/17.1.X.Y.Z-VAL/AtlasCAFHLT/rel_4/NICOS_area/NICOS_atntest171XYZVALAtlasCAFHLT32BS5G4AtlasCAFHLTOpt/triggertest_testconfiguration_work/ ATN page] for !TriggerTest project shows several unit tests that should be checked by the shifter.
  * *Bug (Bug.py)* - refers to a specific bug on the [https://savannah.cern.ch/bugs/?group=atlas-trig Savannah] bug tracker.
  * *!BugTracker (Bug.py)* - refers to a local repository of bugs hardcoded in Bug.py. Basically, all common bugs that appeared in the last few days are entered into this local bug database along with unique "greppable" strings that can be used to identify each bug from the log files.

= Adding new bugs =
If you detect a test failure that could not be matched against the existing bug database in _Bug.py_, please add a corresponding entry for future users. It is also likely that this would save you time tomorrow, because bugs are rarely fixed within one day of appearance.

Basically, once you identify a unique pattern in the log extract (either tail or error extracts are fine), add them via _BugTracker.add()_. You can quickly test this addition by running:
{{{
./Bug.py http://www.link.to/bug/log/extract
}}}
If the pattern was entered correctly, you should see a match.

Be very careful not to add too-general patterns that might match the wrong bug. Also, make sure to escape "[","]","(",")" and other special regex characters.